{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee26e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive call,  \n",
      "a function mirrors itself—  \n",
      "base case guards.\n",
      "\n",
      "Each step peels layers,  \n",
      "stack remembers the path back,  \n",
      "until depth ends.\n",
      "\n",
      "Think of a mirror,  \n",
      "reflecting into deeper light—  \n",
      "ends when no more glass.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from agents import Agent, OpenAIChatCompletionsModel, Runner, SQLiteSession\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "endpoint = os.environ[\"LMSTUDIO_API_URL\"]\n",
    "api_key = os.environ[\"LMSTUDIO_API_KEY\"]\n",
    "\n",
    "model = OpenAIChatCompletionsModel( \n",
    "    model=\"gemma-3-4b-it-qat\",\n",
    "    openai_client=AsyncOpenAI(base_url=endpoint, api_key=api_key)\n",
    ")\n",
    "\n",
    "\n",
    "session_id = \"conversation_123\"\n",
    "session = SQLiteSession(session_id)\n",
    "\n",
    "haiku_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "result = await Runner.run(haiku_agent, \"Tell me about recursion in programming.\", session=session)\n",
    "print(result.final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec707893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rückruf im Code,  \n",
      "eine Funktion spiegelt sich –  \n",
      "Basisfall schützt.\n",
      "\n",
      "Jeder Schritt zerschneidet Schichten,  \n",
      "Stack erinnert den Weg zurück,  \n",
      "bis die Tiefe endet.\n",
      "\n",
      "Stell dir einen Spiegel vor,  \n",
      "der in immer tiefere Lichtreflexionen führt –  \n",
      "endet, wenn kein Glas mehr bleibt.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(haiku_agent, \"Translate this into german.\", session=session)\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38113a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] get_weather called\n",
      "Sky clear, gentle breeze—  \n",
      "Morning sun warms the city,  \n",
      "Day unfolds, bright light.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature_range: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> Weather:\n",
    "    print(\"[debug] get_weather called\")\n",
    "    return Weather(city=city, temperature_range=\"14-20C\", conditions=\"Sunny with wind.\")\n",
    "\n",
    "\n",
    "haiku_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "\n",
    "result = await Runner.run(haiku_agent, input=\"What's the weather in Tokyo?\")\n",
    "print(result.final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
