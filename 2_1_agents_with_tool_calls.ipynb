{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee26e02",
   "metadata": {},
   "source": [
    "# Open AIs Agent Framework\n",
    "\n",
    "https://openai.com/index/new-tools-for-building-agents/\n",
    "\n",
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcbe5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import set_trace_processors\n",
    "set_trace_processors([]) # disable trace processors for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3449f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calls itself,  \n",
      "Dividing problems in parts,  \n",
      "Stack keeps track of time.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from agents import Agent, OpenAIChatCompletionsModel, Runner, SQLiteSession\n",
    "from openai import AsyncOpenAI, AsyncAzureOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "deployment = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]\n",
    "\n",
    "client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-08-01-preview\")\n",
    "\n",
    "model = OpenAIChatCompletionsModel(\n",
    "    model=deployment,\n",
    "    openai_client=client\n",
    ")\n",
    "\n",
    "\n",
    "session_id = \"conversation_123\"\n",
    "session = SQLiteSession(session_id)\n",
    "\n",
    "haiku_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "result = await Runner.run(haiku_agent, \"Tell me about recursion in programming.\", session=session)\n",
    "print(result.final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec707893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funktion ruft sich selbst,  \n",
      "Teilt Probleme in Teile,  \n",
      "Der Stack zählt die Zeit.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(haiku_agent, \"Translate this into german.\", session=session)\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19777af8",
   "metadata": {},
   "source": [
    "## Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38113a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] get_weather called for city: Tokyo\n",
      "Tokyo's skies are clear,  \n",
      "Temperatures mild and bright,  \n",
      "Winds dance in the sun.  \n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temperature_range: str\n",
    "    conditions: str\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> Weather:\n",
    "    '''Get the current weather for a given city'''\n",
    "\n",
    "    print(f\"[debug] get_weather called for city: {city}\")\n",
    "    return Weather(city=city, temperature_range=\"14-20C\", conditions=\"Sunny with wind.\")\n",
    "\n",
    "@function_tool\n",
    "def schnupsi(a: int, b: int) -> int:\n",
    "    '''Add two numbers\n",
    "    Args:\n",
    "        a: first number\n",
    "        b: second number\n",
    "    Returns:        sum of a and b\n",
    "    '''\n",
    "    print(f\"[debug] schnupsi called with a: {a}, b: {b}\")\n",
    "    return a + b\n",
    "\n",
    "\n",
    "haiku_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You only respond in haikus.\",\n",
    "    model=model,\n",
    "    tools=[get_weather,schnupsi]\n",
    "\n",
    ")\n",
    "\n",
    "result = await Runner.run(haiku_agent, input=\"What's the weather in Tokyo?\")\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d1a17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] schnupsi called with a: 5, b: 10\n",
      "Fünf mal zehn, ja,  \n",
      "Die Antwort ist fünfzehn,  \n",
      "Mathematik spricht.\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(haiku_agent, input=\"Was ist 5 * 10?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d18354",
   "metadata": {},
   "source": [
    "# How can we integrate an MCP Server?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569abb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='add', title=None, description='Add two numbers', inputSchema={'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}, outputSchema={'properties': {'result': {'type': 'integer'}}, 'required': ['result'], 'type': 'object', 'x-fastmcp-wrap-result': True}, icons=None, annotations=None, meta={'_fastmcp': {'tags': []}}), Tool(name='fetch_url', title=None, description='Fetch / download the content of a given URL. Return the HTML content as a string.', inputSchema={'properties': {'url': {'type': 'string'}}, 'required': ['url'], 'type': 'object'}, outputSchema={'properties': {'result': {'type': 'string'}}, 'required': ['result'], 'type': 'object', 'x-fastmcp-wrap-result': True}, icons=None, annotations=None, meta={'_fastmcp': {'tags': []}})]\n",
      "Seven plus twenty,  \n",
      "The answer is twenty-nine,  \n",
      "Math brings joy to life.  \n"
     ]
    }
   ],
   "source": [
    "from agents.mcp import MCPServer, MCPServerStreamableHttp\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "\n",
    "mcp_server = MCPServerStreamableHttp(\n",
    "    name=\"Streamable HTTP Python Server\",\n",
    "    params={\n",
    "        \"url\": \"http://localhost:3333/mcp\",\n",
    "    })\n",
    "\n",
    "await mcp_server.connect()\n",
    "\n",
    "print(await mcp_server.list_tools())   # List available tools on the MCP server\n",
    "\n",
    "haiku_agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"You only respond in haikus.\",\n",
    "        model=model,\n",
    "        mcp_servers=[mcp_server],\n",
    "        model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "    )\n",
    "\n",
    "# Use the `add` tool to add two numbers\n",
    "result = await Runner.run(haiku_agent, input=\"Add these numbers: 7 and 22.\")\n",
    "\n",
    "print(result.final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
