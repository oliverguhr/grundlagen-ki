{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calls - Aufrufen eigener APIs\n",
    "\n",
    "Dieses Notebook zeigt, wie man die Funktionsaufrufe mit dem Azure OpenAI Service verwendet. Funktionen ermöglichen es einem Aufrufer von Chatvervollständigungen, Fähigkeiten zu definieren, die das Modell verwenden kann, um seine\n",
    "Funktionalität in externe Tools und Datenquellen zu erweitern.\n",
    "\n",
    "Sie können mehr über Chat-Funktionen im OpenAI-Blog lesen: https://openai.com/blog/function-calling-and-other-api-updates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Zunächst installieren wir die erforderlichen Abhängigkeiten und importieren die Bibliotheken, die wir verwenden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "deployment = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-08-01-preview\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calls\n",
    "\n",
    "Nachdem die Einrichtung und Authentifizierung abgeschlossen sind, können wir nun Funktionen mit dem Azure OpenAI-Service verwenden. Das ist in folgende Schritte aufgeteilt:\n",
    "\n",
    "1. Definieren Sie die Funktion(en)\n",
    "2. Übergabe der Funktionsdefinition(en) an die Chatvervollständigungs-API\n",
    "3. Aufruf der Funktion mit Argumenten aus der Antwort\n",
    "4. Rückführung der Funktionsantwort in die Chatvervollständigungs-API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Definieren der Funktion(en)\n",
    "\n",
    "Es kann eine Liste von Funktionen definiert werden, die jeweils den Namen der Funktion, eine optionale Beschreibung und die Parameter, die die Funktion akzeptiert (beschrieben als JSON-Schema), enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Übergabe der Funktionsdefinition(en) an die Chatvervollständigungs-API\n",
    "\n",
    "Jetzt können wir die Funktion an die Chatvervollständigungs-API übergeben. Wenn das Modell beschließt, die Funktion aufzurufen, wird ein `finish_reason` von \"tool_calls\" in die Auswahl eingefügt und die Details der aufzurufenden Funktion und ihre Argumente werden in der `message` enthalten sein. Optional können Sie das Schlüsselwortargument `tool_choice` setzen, um das Modell zum Aufruf einer bestimmten Funktion zu zwingen (z.B. `{\"type\": \"function\", \"function\": {\"name\": get_current_weather}}`). Standardmäßig ist dies auf `auto` gesetzt, so dass das Modell selbst entscheiden kann, ob es die Funktion aufrufen will oder nicht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AaPC47xZrGNVabmp2lYqtf1w4K9hU', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HDITVKqY0GW0WTwGLqjqi84V', function=Function(arguments='{\"location\":\"Hamburg, DE\"}', name='get_current_weather'), type='function')]), content_filter_results={})], created=1733240016, model='gpt-4o-mini', object='chat.completion', service_tier=None, system_fingerprint='fp_04751d0b65', usage=CompletionUsage(completion_tokens=18, prompt_tokens=98, total_tokens=116), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Bitten Sie um Klärung, wenn eine Benutzeranfrage mehrdeutig ist.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Wie ist das Wetter heute in Hamburg?\"}\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    tools=functions,\n",
    ")\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anhängen der Antwort auf den Tool Call an die Nachrichtenliste\n",
    "messages.append(chat_completion.choices[0].message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Aufruf einer Funktion mit den Argumenten aus der Antwort\n",
    "\n",
    "Der Name des Funktionsaufrufs ist derjenige, der ursprünglich angegeben wurde, und die Argumente enthalten JSON, das dem in der Funktionsdefinition enthaltenen Schema entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_weather\n",
      "{\"location\":\"Hamburg, DE\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_current_weather(request):\n",
    "    \"\"\"\n",
    "    Demo function - do something useful here.\n",
    "    \"\"\"\n",
    "    location = request.get(\"location\")\n",
    "    unit = request.get(\"unit\")\n",
    "    return {\"temperature\": \"22\", \"unit\": unit, \"description\": f\"Wetter für {location}: Wolkig mit der aussicht auf Fleischbällchen\"}\n",
    "\n",
    "tool_call = chat_completion.choices[0].message.tool_calls[0].function\n",
    "tool_call_id = chat_completion.choices[0].message.tool_calls[0].id\n",
    "print(tool_call.name)\n",
    "print(tool_call.arguments)\n",
    "\n",
    "if tool_call.name == \"get_current_weather\":\n",
    "    response = get_current_weather(json.loads(tool_call.arguments))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Rückführung des Tool Calls in die Chatvervollständigungs-API\n",
    "\n",
    "Die Antwort der Funktion sollte in eine neue Nachricht serialisiert werden, deren Rolle auf „tool“ gesetzt ist. Nun wird das Modell die Antwortdaten verwenden, um seine Antwort zu formulieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Wetter heute in Hamburg ist wolkig mit einer Temperatur von 22 Grad. Es besteht die Aussicht auf \"Fleischbällchen\". (Hinweis: Dies könnte ein humorvoller oder metaphorischer Ausdruck sein.)\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"tool_call_id\": tool_call_id,\n",
    "        \"content\": json.dumps(response)\n",
    "    }\n",
    ")\n",
    "\n",
    "function_completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages    \n",
    ")\n",
    "\n",
    "print(function_completion.choices[0].message.content.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a5103089ab7e7c666b279eeded403fcec76de49a40685dbdfe9f9c78ad97c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
