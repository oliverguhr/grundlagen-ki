{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"text-classification\", model=\"oliverguhr/german-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment(\"Das Auto ist gar nicht mal so gut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment([\"Dieser Film ist weder witzig noch intelligent\", \"Das Produkt ist ohne schwächen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de_translator = pipeline(\"translation_en_to_de\")\n",
    "en_de_translator(\"This could make your life easier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "sequence_to_classify = \"Angela Merkel ist eine Politikerin in Deutschland und war Vorsitzende der CDU\"\n",
    "candidate_labels = [\"politics\", \"economy\", \"entertainment\", \"environment\"]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output[\"labels\"])\n",
    "print(output[\"scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bildverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild](https://unsplash.com/photos/9YUsgVnnsTk/download?ixid=M3wxMjA3fDB8MXxhbGx8N3x8fHx8fHx8MTcxNzQyOTYxMnw&force=true&w=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image_classifier = pipeline(task=\"zero-shot-image-classification\", model=\"openai/clip-vit-large-patch14-336\")\n",
    "\n",
    "# load image\n",
    "\n",
    "image = Image.open(\"data/city.jpg\")\n",
    "\n",
    "# inference\n",
    "outputs = image_classifier(image, candidate_labels=[\"Berlin\",\"Dresden\", \"New York\", \"Leipzig\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6927676ac05c423a9fecede98f219170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea953cece4c4735adf885e990344ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67bd4c3b0914aee85a216bd2dac15a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler%2Fscheduler_config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c612eeaf9563492193df9586c88e7f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2%2Fconfig.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c12d45afb5747c093dfd0eb7862f50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24bb2a623a948e7ad142c010bc2fdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44339f11ed7440b5a1acf395556d4f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer%2Ftokenizer_config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e424e249a5e41b7b6fcbf15e8e01d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer%2Fspecial_tokens_map.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c995824dccd24ae1ae17b3a4e8858644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer%2Fmerges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac55fee30b24f8b8bdc77892e556de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder%2Fconfig.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11df5afeb55c47219efd0f3d26f0fbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer%2Fvocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e676266b42749a2b555307e72ceb0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2%2Ftokenizer_config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e910c1d10e4948cab59b6c84ae957be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2%2Fspecial_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1becc7bf8ac941d78e21dd5d2f50d48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be1873d34bc43e18ac8ff42e1078163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae%2Fconfig.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd56a770cd44a7e90191a69778c3cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df94c77f3cc4ec0a88f7f3071603ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet%2Fconfig.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for this example you will need a dedicated GPU with >8GB of VRAM\n",
    "\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
    "\n",
    "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audioverarbeitung\n",
    "\n",
    "[Ich bin ein Berliner](https://www.youtube.com/watch?v=hJNM0C-7lPk&t=15s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um dieses Beispiel auszuführen braucht man ffmpeg \n",
    "#!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"openai/whisper-small\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_id,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,    \n",
    ")\n",
    "\n",
    "\n",
    "result = pipe(\"./data/speech.mp3\")\n",
    "\n",
    "result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
