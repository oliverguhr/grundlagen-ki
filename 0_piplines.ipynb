{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/openai/.local/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: Pillow in /home/openai/.local/lib/python3.10/site-packages (10.3.0)\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.28.0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/openai/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/openai/.local/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers) (4.6.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/openai/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/openai/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/openai/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers Pillow diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/openai/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"text-classification\", model=\"oliverguhr/german-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9986610412597656}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"Das Auto ist gar nicht mal so gut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9850800633430481},\n",
       " {'label': 'positive', 'score': 0.9774582386016846}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment([\"Dieser Film ist weder witzig noch intelligent\", \"Das Produkt ist ohne schwächen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/openai/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Das wird Ihr Leben erleichtern.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_de_translator = pipeline(\"translation_en_to_de\")\n",
    "en_de_translator(\"This could make your life easier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 'economy', 'environment', 'entertainment']\n",
      "[0.9658799171447754, 0.022846776992082596, 0.007333964109420776, 0.003939350135624409]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "sequence_to_classify = \"Angela Merkel ist eine Politikerin in Deutschland und war Vorsitzende der CDU\"\n",
    "candidate_labels = [\"politics\", \"economy\", \"entertainment\", \"environment\"]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output[\"labels\"])\n",
    "print(output[\"scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bildverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild](https://unsplash.com/photos/9YUsgVnnsTk/download?ixid=M3wxMjA3fDB8MXxhbGx8N3x8fHx8fHx8MTcxNzQyOTYxMnw&force=true&w=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9848644733428955, 'label': 'Dresden'},\n",
       " {'score': 0.014148855581879616, 'label': 'Leipzig'},\n",
       " {'score': 0.000986547558568418, 'label': 'Berlin'},\n",
       " {'score': 8.302540521754054e-08, 'label': 'New York'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image_classifier = pipeline(task=\"zero-shot-image-classification\", model=\"openai/clip-vit-large-patch14-336\")\n",
    "\n",
    "# load image\n",
    "url = 'https://unsplash.com/photos/9YUsgVnnsTk/download?ixid=M3wxMjA3fDB8MXxhbGx8N3x8fHx8fHx8MTcxNzQyOTYxMnw&force=true&w=640'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# inference\n",
    "outputs = image_classifier(url, candidate_labels=[\"Berlin\",\"Dresden\", \"New York\", \"Leipzig\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Fetching 18 files: 100%|██████████| 18/18 [00:21<00:00,  1.20s/it]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:22<00:00,  3.14s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
    "\n",
    "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation\n",
    "\n",
    "# bilder\n",
    "\n",
    "# audio\n",
    "\n",
    "https://www.americanrhetoric.com/mp3clipsXE/politicalspeeches/jfkberlinspeechARXE.mp3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audioverarbeitung\n",
    "\n",
    "[Ich bin ein Berliner](https://www.youtube.com/watch?v=hJNM0C-7lPk&t=15s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um dieses Beispiel auszuführen braucht man ffmpeg \n",
    "#!sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I am proud to come to this city as the guest of your distinguished mayor who has symbolized throughout the world the fighting spirit of West Berlin. And I am proud to visit the Federal Republic with your distinguished Chancellor who for so many years has committed Germany to democracy and freedom and progress and to come here in the company of my fellow American General Clay who has been in this city during its great moments of crisis and will come again if ever needed. Two thousand years ago, two thousand years ago, the proudest boast was Kiwis Romanus Sum. Today in the world of freedom the't understand or say they don't. What is the great issue between the free world and the communist world. Let them come to Berlin. There are some who say that communism is the wave of the future, let them come to Berlin. And there are some who say in Europe and elsewhere we can work with the communists. Let them come to Berlin. And there are even a few who say that it's true that communism is an evil system, but it permits us to make economic progress. Freedom has many difficulties and democracy is not perfect but we have never had to put a wall up to keep our people in to prevent them from leaving us. I want to say on behalf of my countrymen who live many miles away on the other side of the Atlantic, who are far distant from you, that they take the greatest pride that they have been able to share with you even from a distance the story of the last 18 years. I know of no town, no city that has been besieged for 18 years, that still lives with the vitality and the force and the hope and the determination of the city of West Berlin. While the wall is the most obvious and vivid demonstration of the failures of the communist system. For all the world to see, we take no satisfaction in it. For it is, as your mayor has said, an offense not only against history, but an offense against humanity, separating families, dividing husbands and wives and brothers and sisters, and dividing a people who wish to be joined together. What is true of this city is true of Germany. Real lasting peace in Europe can never be assured as long as one German out of four is denied the elementary right of free men and that is to make a free choice. In 18 years of peace and good faith this generation of Germans has earned the right to be free, including the right to unite their families and their nation in lasting peace with goodwill to all people. You live in a defended island of freedom, but your life is part of the main. So let me ask you as I close to lift your eyes beyond the dangers of today to the hopes of tomorrow, beyond the freedom merely of this city of Berlin or your country of Germany, to the advance of freedom everywhere, beyond the wall, to the day of peace with justice, beyond yourselves ourselves to all mankind freedom is indivisible and when one man is enslaved all are not free when all are free then we look and look forward to that day when this city will be joined as one and this country and this great continent of Europe in a peaceful and hopeful globe. When that day finally comes, as it will, the people of West Berlin can take sober satisfaction in the fact that they were in the front lines for almost two decades. All free men, wherever they may live, are citizens of Berlin. And therefore, as a free man, I take pride in the words, Ish bin Ein Berliner.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_id = \"openai/whisper-medium\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_id,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    device = \"cuda:0\"\n",
    ")\n",
    "\n",
    "\n",
    "result = pipe(\"./data/speech.mp3\")\n",
    "\n",
    "result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
