{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden und durchsuchen von eigenen Daten\n",
    "\n",
    "1. Zuerst laden wir die Dokumente aus dem docs Verzeichniss\n",
    "2. Dann teilen wir die Dokumente in kleine Segmente auf\n",
    "3. Dann erstellen wir daraus einen Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('./docs', glob=\"**/*.md\")\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Zeichen in Text {len(data[1].page_content)}\")\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie können wir die Texte in kürzere Abschnitte unterteilen?\n",
    "\n",
    "Web Demo [Chunk Visualizer](https://huggingface.co/spaces/m-ric/chunk_visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "print(len(all_splits))\n",
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "chroma = chromadb.Client()\n",
    "\n",
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "try:\n",
    "    chroma.delete_collection(\"documents\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = chroma.get_or_create_collection(\"documents\",embedding_function=sentence_transformer_ef)\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=[item.page_content for item in all_splits], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[item.metadata for item in all_splits], # filter on these!\n",
    "    ids=[str(id) for id in range(0,len(all_splits))], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"Was ist die MMS?\"],\n",
    "    n_results=4,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    #where_document={\"$contains\":\"Oliver\"}  # optional filter\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben \n",
    "\n",
    "* Trage informationen ein - Findet sie die suche wieder?\n",
    "* Wie groß sollte die Chuck Size sein?\n",
    "* Finde die ehemaligen Geschäftsführer\n",
    "\n",
    "\n",
    "Optional \n",
    "* Open AI Embeddings\n",
    "* BGE Embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
