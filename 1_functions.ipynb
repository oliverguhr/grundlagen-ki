{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure functions example\n",
    "\n",
    "Dieses Notebook zeigt, wie man die Funktionsaufrufe mit dem Azure OpenAI Service verwendet. Funktionen ermöglichen es einem Aufrufer von Chatvervollständigungen, Fähigkeiten zu definieren, die das Modell verwenden kann, um seine\n",
    "Funktionalität in externe Tools und Datenquellen zu erweitern.\n",
    "\n",
    "Sie können mehr über Chat-Funktionen im OpenAI-Blog lesen: https://openai.com/blog/function-calling-and-other-api-updates\n",
    "\n",
    "\n",
    "**HINWEIS**: Chat-Funktionen erfordern Modellversionen, die mit den Labels gpt-4 und gpt-35-turbo `-0125` beginnen. Sie werden von älteren Versionen der Modelle nicht unterstützt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Zunächst installieren wir die erforderlichen Abhängigkeiten und importieren die Bibliotheken, die wir verwenden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-09-01-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt-35-turbo-0125\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Nachdem die Einrichtung und Authentifizierung abgeschlossen sind, können wir nun Funktionen mit dem Azure OpenAI-Service verwenden. Das ist in folgende Schritte aufgeteilt:\n",
    "\n",
    "1. Definieren Sie die Funktion(en)\n",
    "2. Übergabe der Funktionsdefinition(en) an die Chatvervollständigungs-API\n",
    "3. Aufruf der Funktion mit Argumenten aus der Antwort\n",
    "4. Rückführung der Funktionsantwort in die Chatvervollständigungs-API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Definieren der Funktion(en)\n",
    "\n",
    "Es kann eine Liste von Funktionen definiert werden, die jeweils den Namen der Funktion, eine optionale Beschreibung und die Parameter, die die Funktion akzeptiert (beschrieben als JSON-Schema), enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Übergabe der Funktionsdefinition(en) an die Chatvervollständigungs-API\n",
    "\n",
    "Jetzt können wir die Funktion an die Chatvervollständigungs-API übergeben. Wenn das Modell beschließt, die Funktion aufzurufen, wird ein `finish_reason` von \"tool_calls\" in die Auswahl eingefügt und die Details der aufzurufenden Funktion und ihre Argumente werden in der `message` enthalten sein. Optional können Sie das Schlüsselwortargument `tool_choice` setzen, um das Modell zum Aufruf einer bestimmten Funktion zu zwingen (z.B. `{\"type\": \"function\", \"function\": {\"name\": get_current_weather}}`). Standardmäßig ist dies auf `auto` gesetzt, so dass das Modell selbst entscheiden kann, ob es die Funktion aufrufen will oder nicht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9AfAGFQplaVjTKKP1SkHh5GRimlSd', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BMDj0T63DKrYECNzANfFhyDe', function=Function(arguments='{\"location\":\"Hamburg\"}', name='get_current_weather'), type='function')]), content_filter_results={})], created=1712328544, model='gpt-35-turbo', object='chat.completion', system_fingerprint='fp_2f57f81c11', usage=CompletionUsage(completion_tokens=16, prompt_tokens=125, total_tokens=141), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Stellen keine Vermutungen darüber an, welche Werte Sie in die Funktionen eingeben sollen. Bitten Sie um Klärung, wenn eine Benutzeranfrage mehrdeutig ist.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Wie ist das Wetter heute in Hamburg?\"}\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    tools=functions,\n",
    ")\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BMDj0T63DKrYECNzANfFhyDe', function=Function(arguments='{\"location\":\"Hamburg\"}', name='get_current_weather'), type='function')]), content_filter_results={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Aufruf einer Funktion mit den Argumenten aus der Antwort\n",
    "\n",
    "Der Name des Funktionsaufrufs ist derjenige, der ursprünglich angegeben wurde, und die Argumente enthalten JSON, das dem in der Funktionsdefinition enthaltenen Schema entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_current_weather\n",
      "{\"location\":\"Hamburg\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_current_weather(request):\n",
    "    \"\"\"\n",
    "    Demo function - do something useful here.\n",
    "    \"\"\"\n",
    "    location = request.get(\"location\")\n",
    "    unit = request.get(\"unit\")\n",
    "    return {\"temperature\": \"22\", \"unit\": \"celsius\", \"description\": \"Wolkig mit der aussicht auf Fleischbällchen\"}\n",
    "\n",
    "function_call = chat_completion.choices[0].message.tool_calls[0].function\n",
    "print(function_call.name)\n",
    "print(function_call.arguments)\n",
    "\n",
    "if function_call.name == \"get_current_weather\":\n",
    "    response = get_current_weather(json.loads(function_call.arguments))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Feed function response back into chat completions API\n",
    "\n",
    "The response from the function should be serialized into a new message with the role set to \"function\". Now the model will use the response data to formulate its answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Wetter heute in Hamburg ist wolkig mit der Aussicht auf Fleischbällchen. Die Temperatur beträgt 22 Grad Celsius.\n"
     ]
    }
   ],
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"content\": json.dumps(response)\n",
    "    }\n",
    ")\n",
    "\n",
    "function_completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=messages,\n",
    "    tools=functions,\n",
    ")\n",
    "\n",
    "print(function_completion.choices[0].message.content.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a5103089ab7e7c666b279eeded403fcec76de49a40685dbdfe9f9c78ad97c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
